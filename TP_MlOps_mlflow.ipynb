{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mettre en place MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow\n",
      "  Using cached mlflow-2.16.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting mlflow-skinny==2.16.0 (from mlflow)\n",
      "  Using cached mlflow_skinny-2.16.0-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: Flask<4 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from mlflow) (3.0.3)\n",
      "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
      "  Using cached alembic-1.13.2-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting docker<8,>=4.0.0 (from mlflow)\n",
      "  Using cached docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting graphene<4 (from mlflow)\n",
      "  Using cached graphene-3.3-py2.py3-none-any.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from mlflow) (3.7)\n",
      "Collecting matplotlib<4 (from mlflow)\n",
      "  Using cached matplotlib-3.9.2-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<3 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from mlflow) (2.1.1)\n",
      "Collecting pandas<3 (from mlflow)\n",
      "  Using cached pandas-2.2.2-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Collecting pyarrow<18,>=4.0.0 (from mlflow)\n",
      "  Using cached pyarrow-17.0.0-cp311-cp311-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting scikit-learn<2 (from mlflow)\n",
      "  Using cached scikit_learn-1.5.1-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: scipy<2 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from mlflow) (1.14.1)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from mlflow) (2.0.34)\n",
      "Requirement already satisfied: Jinja2<4,>=3.0 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from mlflow) (3.1.4)\n",
      "Requirement already satisfied: waitress<4 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from mlflow) (3.0.0)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from mlflow-skinny==2.16.0->mlflow) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from mlflow-skinny==2.16.0->mlflow) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle<4 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from mlflow-skinny==2.16.0->mlflow) (3.0.0)\n",
      "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.16.0->mlflow)\n",
      "  Using cached databricks_sdk-0.32.0-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting gitpython<4,>=3.1.9 (from mlflow-skinny==2.16.0->mlflow)\n",
      "  Using cached GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting importlib-metadata!=4.7.0,<9,>=3.7.0 (from mlflow-skinny==2.16.0->mlflow)\n",
      "  Using cached importlib_metadata-8.4.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==2.16.0->mlflow)\n",
      "  Using cached opentelemetry_api-1.27.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==2.16.0->mlflow)\n",
      "  Using cached opentelemetry_sdk-1.27.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: packaging<25 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from mlflow-skinny==2.16.0->mlflow) (24.1)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from mlflow-skinny==2.16.0->mlflow) (5.28.0)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from mlflow-skinny==2.16.0->mlflow) (6.0.2)\n",
      "Collecting requests<3,>=2.17.3 (from mlflow-skinny==2.16.0->mlflow)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from mlflow-skinny==2.16.0->mlflow) (0.5.1)\n",
      "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
      "  Using cached Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from alembic!=1.10.0,<2->mlflow) (4.12.2)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from docker<8,>=4.0.0->mlflow) (306)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from docker<8,>=4.0.0->mlflow) (2.2.2)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from Flask<4->mlflow) (3.0.4)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from Flask<4->mlflow) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from Flask<4->mlflow) (1.8.2)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from graphene<4->mlflow) (3.2.4)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Using cached graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: aniso8601<10,>=8 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from graphene<4->mlflow) (9.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from Jinja2<4,>=3.0->mlflow) (2.1.5)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib<4->mlflow)\n",
      "  Using cached contourpy-1.3.0-cp311-cp311-win_amd64.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from matplotlib<4->mlflow) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from matplotlib<4->mlflow) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from matplotlib<4->mlflow) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from matplotlib<4->mlflow) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from matplotlib<4->mlflow) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from pandas<3->mlflow) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from pandas<3->mlflow) (2024.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from click<9,>=7.0->mlflow-skinny==2.16.0->mlflow) (0.4.6)\n",
      "Collecting google-auth~=2.0 (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.0->mlflow)\n",
      "  Using cached google_auth-2.34.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow-skinny==2.16.0->mlflow)\n",
      "  Using cached gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.16.0->mlflow) (3.20.1)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.16.0->mlflow)\n",
      "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.48b0 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.16.0->mlflow)\n",
      "  Using cached opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib<4->mlflow) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.16.0->mlflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.16.0->mlflow) (3.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.16.0->mlflow) (2024.8.30)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.16.0->mlflow) (1.16.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.16.0->mlflow) (5.0.1)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.0->mlflow)\n",
      "  Using cached pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.0->mlflow)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.0->mlflow) (0.6.0)\n",
      "Using cached mlflow-2.16.0-py3-none-any.whl (26.6 MB)\n",
      "Using cached mlflow_skinny-2.16.0-py3-none-any.whl (5.6 MB)\n",
      "Using cached alembic-1.13.2-py3-none-any.whl (232 kB)\n",
      "Using cached docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "Using cached graphene-3.3-py2.py3-none-any.whl (128 kB)\n",
      "Using cached matplotlib-3.9.2-cp311-cp311-win_amd64.whl (7.8 MB)\n",
      "Using cached pandas-2.2.2-cp311-cp311-win_amd64.whl (11.6 MB)\n",
      "Using cached pyarrow-17.0.0-cp311-cp311-win_amd64.whl (25.2 MB)\n",
      "Using cached scikit_learn-1.5.1-cp311-cp311-win_amd64.whl (11.0 MB)\n",
      "Using cached contourpy-1.3.0-cp311-cp311-win_amd64.whl (217 kB)\n",
      "Using cached databricks_sdk-0.32.0-py3-none-any.whl (551 kB)\n",
      "Using cached GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "Using cached graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Using cached importlib_metadata-8.4.0-py3-none-any.whl (26 kB)\n",
      "Using cached opentelemetry_api-1.27.0-py3-none-any.whl (63 kB)\n",
      "Using cached opentelemetry_sdk-1.27.0-py3-none-any.whl (110 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl (149 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached Mako-1.3.5-py3-none-any.whl (78 kB)\n",
      "Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Using cached gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Using cached google_auth-2.34.0-py2.py3-none-any.whl (200 kB)\n",
      "Using cached pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Installing collected packages: rsa, requests, pyasn1-modules, pyarrow, Mako, importlib-metadata, graphql-relay, gitdb, deprecated, contourpy, scikit-learn, pandas, opentelemetry-api, matplotlib, graphene, google-auth, gitpython, docker, alembic, opentelemetry-semantic-conventions, databricks-sdk, opentelemetry-sdk, mlflow-skinny, mlflow\n",
      "Successfully installed Mako-1.3.5 alembic-1.13.2 contourpy-1.3.0 databricks-sdk-0.32.0 deprecated-1.2.14 docker-7.1.0 gitdb-4.0.11 gitpython-3.1.43 google-auth-2.34.0 graphene-3.3 graphql-relay-3.2.0 importlib-metadata-8.4.0 matplotlib-3.9.2 mlflow-2.16.0 mlflow-skinny-2.16.0 opentelemetry-api-1.27.0 opentelemetry-sdk-1.27.0 opentelemetry-semantic-conventions-0.48b0 pandas-2.2.2 pyarrow-17.0.0 pyasn1-modules-0.4.0 requests-2.32.3 rsa-4.9 scikit-learn-1.5.1\n",
      "Requirement already satisfied: jinja2 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (3.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from jinja2) (2.1.5)\n",
      "Requirement already satisfied: Flask in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (3.0.3)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from Flask) (3.0.4)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from Flask) (3.1.4)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from Flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from Flask) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from Flask) (1.8.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from click>=8.1.3->Flask) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from Jinja2>=3.1.2->Flask) (2.1.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (65.5.0)\n"
     ]
    }
   ],
   "source": [
    "# Install the following librairies (it is better to create a venv (or conda) virtual environment first and install these librairies in it)\n",
    "!pip install mlflow\n",
    "!pip install --upgrade jinja2\n",
    "!pip install --upgrade Flask\n",
    "!pip install setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# starts an MLflow server locally.\n",
    "!mlflow server --host 127.0.0.1 --port 5000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initier une nouvelle Exp√©rience.\n",
    "\n",
    "D√©marrer des Ex√©cutions au sein d'une Exp√©rience.\n",
    "\n",
    "Documenter les param√®tres, les m√©triques et les balises pour vos Ex√©cutions.\n",
    "\n",
    "Enregistrer des artefacts li√©s aux ex√©cutions, tels que des mod√®les, des tableaux, des graphiques, et plus encore.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow import MlflowClient\n",
    "from pprint import pprint\n",
    "from sklearn.ensemble import RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to connect to the tracking server, we‚Äôll need to use the uri that we assigned the server when we started it.\n",
    "\n",
    "client = MlflowClient(tracking_uri=\"http://127.0.0.1:5000\")\n",
    "\n",
    "#it allows programmatic interaction with the MLflow tracking server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons maintenant une interface client vers le serveur de suivi qui peut √† la fois envoyer des donn√©es au serveur de suivi et en r√©cup√©rer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Experiment: artifact_location='mlflow-artifacts:/0', creation_time=1725646407256, experiment_id='0', last_update_time=1725646407256, lifecycle_stage='active', name='Default', tags={}>]\n"
     ]
    }
   ],
   "source": [
    "all_experiments = client.search_experiments()\n",
    "\n",
    "print(all_experiments)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cr√©er une exp√©rience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fournir une description de l'exp√©rience qui appara√Ætra dans l'interface utilisateur\n",
    "experiment_description = (\n",
    "    \"Ceci est un projet de pr√©diction de d√©faut de paiement des clients. \"\n",
    "    \"Cette exp√©rience contient les mod√®les pour la pr√©diction de d√©faut de cr√©dit.\"\n",
    ")\n",
    "\n",
    "# Fournir des balises (tags) recherchables qui d√©finissent les caract√©ristiques des ex√©cutions (Runs)\n",
    "# qui feront partie de cette exp√©rience\n",
    "experiment_tags = {\n",
    "    \"project_name\": \"credit-default-prediction\",\n",
    "    \"business_unit\": \"risk-management\",\n",
    "    \"team\": \"data-science\",\n",
    "    \"project_quarter\": \"Q3-2023\",\n",
    "    \"mlflow.note.content\": experiment_description,\n",
    "}\n",
    "\n",
    "# Cr√©er l'exp√©rience en fournissant un nom unique\n",
    "credit_default_experiment = client.create_experiment(\n",
    "    name=\"Credit_Default_Models\", tags=experiment_tags\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_experiment_id': '892581525100417762', '_name': 'Apple_Models', '_artifact_location': 'mlflow-artifacts:/892581525100417762', '_lifecycle_stage': 'active', '_tags': {'mlflow.note.content': 'This is the grocery forecasting project. This experiment contains the produce models for apples.', 'project_name': 'grocery-forecasting', 'project_quarter': 'Q3-2023', 'store_dept': 'produce', 'team': 'stores-ml'}, '_creation_time': 1725647809507, '_last_update_time': 1725647809507}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Utiliser search_experiments() pour rechercher les exp√©riences par la balise project_name\n",
    "\n",
    "credit_default_experiment = client.search_experiments(\n",
    "    filter_string=\"tags.`project_name` = 'credit-default-prediction'\"\n",
    ")\n",
    "\n",
    "print(vars(credit_default_experiment[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger les donn√©es\n",
    "data = pd.read_csv(\"Loan_Data(1).csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>credit_lines_outstanding</th>\n",
       "      <th>loan_amt_outstanding</th>\n",
       "      <th>total_debt_outstanding</th>\n",
       "      <th>income</th>\n",
       "      <th>years_employed</th>\n",
       "      <th>fico_score</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8153374</td>\n",
       "      <td>0</td>\n",
       "      <td>5221.545193</td>\n",
       "      <td>3915.471226</td>\n",
       "      <td>78039.38546</td>\n",
       "      <td>5</td>\n",
       "      <td>605</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7442532</td>\n",
       "      <td>5</td>\n",
       "      <td>1958.928726</td>\n",
       "      <td>8228.752520</td>\n",
       "      <td>26648.43525</td>\n",
       "      <td>2</td>\n",
       "      <td>572</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2256073</td>\n",
       "      <td>0</td>\n",
       "      <td>3363.009259</td>\n",
       "      <td>2027.830850</td>\n",
       "      <td>65866.71246</td>\n",
       "      <td>4</td>\n",
       "      <td>602</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4885975</td>\n",
       "      <td>0</td>\n",
       "      <td>4766.648001</td>\n",
       "      <td>2501.730397</td>\n",
       "      <td>74356.88347</td>\n",
       "      <td>5</td>\n",
       "      <td>612</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4700614</td>\n",
       "      <td>1</td>\n",
       "      <td>1345.827718</td>\n",
       "      <td>1768.826187</td>\n",
       "      <td>23448.32631</td>\n",
       "      <td>6</td>\n",
       "      <td>631</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  credit_lines_outstanding  loan_amt_outstanding  \\\n",
       "0      8153374                         0           5221.545193   \n",
       "1      7442532                         5           1958.928726   \n",
       "2      2256073                         0           3363.009259   \n",
       "3      4885975                         0           4766.648001   \n",
       "4      4700614                         1           1345.827718   \n",
       "\n",
       "   total_debt_outstanding       income  years_employed  fico_score  default  \n",
       "0             3915.471226  78039.38546               5         605        0  \n",
       "1             8228.752520  26648.43525               2         572        1  \n",
       "2             2027.830850  65866.71246               4         602        0  \n",
       "3             2501.730397  74356.88347               5         612        0  \n",
       "4             1768.826187  23448.32631               6         631        0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging our first runs with MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function call sets the global tracking URI for the current session.\n",
    "# It‚Äôs a convenient way to configure the tracking server URI without creating a separate client instance.\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets the current active experiment to the \"Apple_Models\" experiment and\n",
    "# returns the Experiment metadata\n",
    "# D√©finir l'exp√©rience active pour votre projet\n",
    "customer_default_experiment = mlflow.set_experiment(\"Client_Default_Prediction\")\n",
    "\n",
    "# Define a run name for this iteration of training.\n",
    "# If this is not set, a unique name will be auto-generated for your run.\n",
    "run_name = \"default_rf_test\"\n",
    "\n",
    "# Define an artifact path that the model will be saved to.\n",
    "# D√©finir le chemin des artefacts\n",
    "artifact_path = \"rf_default_model\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alban\\OneDrive\\Documents\\MLolp\\projet-main\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "c:\\Users\\alban\\OneDrive\\Documents\\MLolp\\projet-main\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2024/09/07 09:08:28 INFO mlflow.tracking._tracking_service.client: üèÉ View run random_forest_default_prediction at: http://127.0.0.1:5000/#/experiments/0/runs/bb79a13ebccd4ee8a36b45ae9326efdf.\n",
      "2024/09/07 09:08:28 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:5000/#/experiments/0.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "\n",
    "# Diviser les donn√©es en caract√©ristiques (X) et cible (y)\n",
    "X = data.drop(columns=[\"customer_id\", \"default\"])  # Enlever les colonnes 'customer_id' et 'default'\n",
    "y = data[\"default\"]\n",
    "\n",
    "# Diviser les donn√©es en ensembles d'entra√Ænement et de validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Param√®tres du mod√®le RandomForestClassifier\n",
    "params = {\n",
    "    \"n_estimators\": 100,\n",
    "    \"max_depth\": 6,\n",
    "    \"min_samples_split\": 10,\n",
    "    \"min_samples_leaf\": 4,\n",
    "    \"bootstrap\": True,\n",
    "    \"oob_score\": False,\n",
    "    \"random_state\": 888,\n",
    "}\n",
    "\n",
    "# Entra√Æner le mod√®le RandomForestClassifier\n",
    "rf = RandomForestClassifier(class_weight='balanced',**params)\n",
    "\n",
    "# Ajuster le mod√®le sur les donn√©es d'entra√Ænement\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Pr√©dire sur l'ensemble de validation\n",
    "y_pred = rf.predict(X_val)\n",
    "\n",
    "# Calculer les m√©triques de classification\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "precision = precision_score(y_val, y_pred)\n",
    "recall = recall_score(y_val, y_pred)\n",
    "\n",
    "# Assembler les m√©triques dans une collection pour les enregistrer\n",
    "metrics = {\"accuracy\": accuracy, \"f1_score\": f1, \"precision\": precision, \"recall\": recall}\n",
    "\n",
    "# D√©marrer le contexte d'ex√©cution MLflow\n",
    "with mlflow.start_run(run_name=\"random_forest_default_prediction\") as run:\n",
    "    # Enregistrer les param√®tres utilis√©s pour l'entra√Ænement du mod√®le\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Enregistrer les m√©triques de performance calcul√©es\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    # Enregistrer une instance du mod√®le entra√Æn√© pour une utilisation ult√©rieure\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=rf, input_example=X_val, artifact_path=\"random_forest_model\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.995875\n",
      "Validation Accuracy: 0.9915\n"
     ]
    }
   ],
   "source": [
    "# Pr√©dire sur l'ensemble d'entra√Ænement\n",
    "y_train_pred = rf.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "# Afficher les scores de pr√©cision\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Validation Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alban\\OneDrive\\Documents\\MLolp\\projet-main\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "c:\\Users\\alban\\OneDrive\\Documents\\MLolp\\projet-main\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2024/09/07 09:20:49 INFO mlflow.tracking._tracking_service.client: üèÉ View run logistic_regression_run_1 at: http://127.0.0.1:5000/#/experiments/286315274138648484/runs/4e7c2243f07a456cb25a630e9a05033e.\n",
      "2024/09/07 09:20:49 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:5000/#/experiments/286315274138648484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run completed with parameters: {'C': 1.0, 'solver': 'liblinear', 'random_state': 42, 'class_weight': 'balanced'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      1652\n",
      "           1       0.91      0.98      0.94       348\n",
      "\n",
      "    accuracy                           0.98      2000\n",
      "   macro avg       0.95      0.98      0.96      2000\n",
      "weighted avg       0.98      0.98      0.98      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "from sklearn.linear_model import LogisticRegression  # Importer LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report  # Importer classification_report\n",
    "\n",
    "# D√©finir l'URI de suivi\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "# Cr√©er ou s√©lectionner l'exp√©rience pour la r√©gression logistique\n",
    "mlflow.set_experiment(\"LogisticRegression_Models\")\n",
    "\n",
    "# D√©finir les param√®tres du mod√®le\n",
    "params = {\"C\": 1.0, \"solver\": 'liblinear', \"random_state\": 42, \"class_weight\": 'balanced'}\n",
    "\n",
    "# D√©marrer un run pour entra√Æner le mod√®le avec les param√®tres d√©finis\n",
    "with mlflow.start_run(run_name=\"logistic_regression_run_1\"):\n",
    "    # Entra√Æner le mod√®le de r√©gression logistique\n",
    "    lr_model = LogisticRegression(**params)\n",
    "    lr_model.fit(X_train, y_train)\n",
    "\n",
    "    # Pr√©dire sur l'ensemble de validation\n",
    "    y_pred = lr_model.predict(X_val)\n",
    "\n",
    "    # Calculer les m√©triques de classification\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    precision = precision_score(y_val, y_pred)\n",
    "    recall = recall_score(y_val, y_pred)\n",
    "\n",
    "    # Assembler les m√©triques dans une collection pour les enregistrer\n",
    "    metrics = {\"accuracy\": accuracy, \"f1_score\": f1, \"precision\": precision, \"recall\": recall}\n",
    "\n",
    "    # Enregistrer les param√®tres et les m√©triques dans MLflow\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    # Enregistrer le mod√®le entra√Æn√© comme artefact\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=lr_model, input_example=X_val, artifact_path=\"logistic_regression_model\"\n",
    "    )\n",
    "\n",
    "    # Afficher le rapport de classification\n",
    "    print(f\"Run completed with parameters: {params}\")\n",
    "    print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"random_forest_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(rf, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
