{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mettre en place MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow\n",
      "  Using cached mlflow-2.16.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting mlflow-skinny==2.16.0 (from mlflow)\n",
      "  Using cached mlflow_skinny-2.16.0-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: Flask<4 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from mlflow) (3.0.3)\n",
      "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
      "  Using cached alembic-1.13.2-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting docker<8,>=4.0.0 (from mlflow)\n",
      "  Using cached docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting graphene<4 (from mlflow)\n",
      "  Using cached graphene-3.3-py2.py3-none-any.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from mlflow) (3.7)\n",
      "Collecting matplotlib<4 (from mlflow)\n",
      "  Using cached matplotlib-3.9.2-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<3 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from mlflow) (2.1.1)\n",
      "Collecting pandas<3 (from mlflow)\n",
      "  Using cached pandas-2.2.2-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Collecting pyarrow<18,>=4.0.0 (from mlflow)\n",
      "  Using cached pyarrow-17.0.0-cp311-cp311-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting scikit-learn<2 (from mlflow)\n",
      "  Using cached scikit_learn-1.5.1-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: scipy<2 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from mlflow) (1.14.1)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from mlflow) (2.0.34)\n",
      "Requirement already satisfied: Jinja2<4,>=3.0 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from mlflow) (3.1.4)\n",
      "Requirement already satisfied: waitress<4 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from mlflow) (3.0.0)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from mlflow-skinny==2.16.0->mlflow) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from mlflow-skinny==2.16.0->mlflow) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle<4 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from mlflow-skinny==2.16.0->mlflow) (3.0.0)\n",
      "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.16.0->mlflow)\n",
      "  Using cached databricks_sdk-0.32.0-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting gitpython<4,>=3.1.9 (from mlflow-skinny==2.16.0->mlflow)\n",
      "  Using cached GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting importlib-metadata!=4.7.0,<9,>=3.7.0 (from mlflow-skinny==2.16.0->mlflow)\n",
      "  Using cached importlib_metadata-8.4.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==2.16.0->mlflow)\n",
      "  Using cached opentelemetry_api-1.27.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==2.16.0->mlflow)\n",
      "  Using cached opentelemetry_sdk-1.27.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: packaging<25 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from mlflow-skinny==2.16.0->mlflow) (24.1)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from mlflow-skinny==2.16.0->mlflow) (5.28.0)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from mlflow-skinny==2.16.0->mlflow) (6.0.2)\n",
      "Collecting requests<3,>=2.17.3 (from mlflow-skinny==2.16.0->mlflow)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from mlflow-skinny==2.16.0->mlflow) (0.5.1)\n",
      "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
      "  Using cached Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from alembic!=1.10.0,<2->mlflow) (4.12.2)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from docker<8,>=4.0.0->mlflow) (306)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from docker<8,>=4.0.0->mlflow) (2.2.2)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from Flask<4->mlflow) (3.0.4)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from Flask<4->mlflow) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from Flask<4->mlflow) (1.8.2)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from graphene<4->mlflow) (3.2.4)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Using cached graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: aniso8601<10,>=8 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from graphene<4->mlflow) (9.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from Jinja2<4,>=3.0->mlflow) (2.1.5)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib<4->mlflow)\n",
      "  Using cached contourpy-1.3.0-cp311-cp311-win_amd64.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from matplotlib<4->mlflow) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from matplotlib<4->mlflow) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from matplotlib<4->mlflow) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from matplotlib<4->mlflow) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from matplotlib<4->mlflow) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from pandas<3->mlflow) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from pandas<3->mlflow) (2024.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from click<9,>=7.0->mlflow-skinny==2.16.0->mlflow) (0.4.6)\n",
      "Collecting google-auth~=2.0 (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.0->mlflow)\n",
      "  Using cached google_auth-2.34.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow-skinny==2.16.0->mlflow)\n",
      "  Using cached gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.16.0->mlflow) (3.20.1)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.16.0->mlflow)\n",
      "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.48b0 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.16.0->mlflow)\n",
      "  Using cached opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib<4->mlflow) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.16.0->mlflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.16.0->mlflow) (3.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.16.0->mlflow) (2024.8.30)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.16.0->mlflow) (1.16.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.16.0->mlflow) (5.0.1)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.0->mlflow)\n",
      "  Using cached pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.0->mlflow)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.0->mlflow) (0.6.0)\n",
      "Using cached mlflow-2.16.0-py3-none-any.whl (26.6 MB)\n",
      "Using cached mlflow_skinny-2.16.0-py3-none-any.whl (5.6 MB)\n",
      "Using cached alembic-1.13.2-py3-none-any.whl (232 kB)\n",
      "Using cached docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "Using cached graphene-3.3-py2.py3-none-any.whl (128 kB)\n",
      "Using cached matplotlib-3.9.2-cp311-cp311-win_amd64.whl (7.8 MB)\n",
      "Using cached pandas-2.2.2-cp311-cp311-win_amd64.whl (11.6 MB)\n",
      "Using cached pyarrow-17.0.0-cp311-cp311-win_amd64.whl (25.2 MB)\n",
      "Using cached scikit_learn-1.5.1-cp311-cp311-win_amd64.whl (11.0 MB)\n",
      "Using cached contourpy-1.3.0-cp311-cp311-win_amd64.whl (217 kB)\n",
      "Using cached databricks_sdk-0.32.0-py3-none-any.whl (551 kB)\n",
      "Using cached GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "Using cached graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Using cached importlib_metadata-8.4.0-py3-none-any.whl (26 kB)\n",
      "Using cached opentelemetry_api-1.27.0-py3-none-any.whl (63 kB)\n",
      "Using cached opentelemetry_sdk-1.27.0-py3-none-any.whl (110 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl (149 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached Mako-1.3.5-py3-none-any.whl (78 kB)\n",
      "Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Using cached gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Using cached google_auth-2.34.0-py2.py3-none-any.whl (200 kB)\n",
      "Using cached pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Installing collected packages: rsa, requests, pyasn1-modules, pyarrow, Mako, importlib-metadata, graphql-relay, gitdb, deprecated, contourpy, scikit-learn, pandas, opentelemetry-api, matplotlib, graphene, google-auth, gitpython, docker, alembic, opentelemetry-semantic-conventions, databricks-sdk, opentelemetry-sdk, mlflow-skinny, mlflow\n",
      "Successfully installed Mako-1.3.5 alembic-1.13.2 contourpy-1.3.0 databricks-sdk-0.32.0 deprecated-1.2.14 docker-7.1.0 gitdb-4.0.11 gitpython-3.1.43 google-auth-2.34.0 graphene-3.3 graphql-relay-3.2.0 importlib-metadata-8.4.0 matplotlib-3.9.2 mlflow-2.16.0 mlflow-skinny-2.16.0 opentelemetry-api-1.27.0 opentelemetry-sdk-1.27.0 opentelemetry-semantic-conventions-0.48b0 pandas-2.2.2 pyarrow-17.0.0 pyasn1-modules-0.4.0 requests-2.32.3 rsa-4.9 scikit-learn-1.5.1\n",
      "Requirement already satisfied: jinja2 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (3.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from jinja2) (2.1.5)\n",
      "Requirement already satisfied: Flask in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (3.0.3)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from Flask) (3.0.4)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from Flask) (3.1.4)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from Flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from Flask) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from Flask) (1.8.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from click>=8.1.3->Flask) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (from Jinja2>=3.1.2->Flask) (2.1.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\alban\\onedrive\\documents\\mlolp\\projet-main\\.venv\\lib\\site-packages (65.5.0)\n"
     ]
    }
   ],
   "source": [
    "# Install the following librairies (it is better to create a venv (or conda) virtual environment first and install these librairies in it)\n",
    "!pip install mlflow\n",
    "!pip install --upgrade jinja2\n",
    "!pip install --upgrade Flask\n",
    "!pip install setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# starts an MLflow server locally.\n",
    "!mlflow server --host 127.0.0.1 --port 5000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initier une nouvelle Expérience.\n",
    "\n",
    "Démarrer des Exécutions au sein d'une Expérience.\n",
    "\n",
    "Documenter les paramètres, les métriques et les balises pour vos Exécutions.\n",
    "\n",
    "Enregistrer des artefacts liés aux exécutions, tels que des modèles, des tableaux, des graphiques, et plus encore.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow import MlflowClient\n",
    "from pprint import pprint\n",
    "from sklearn.ensemble import RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to connect to the tracking server, we’ll need to use the uri that we assigned the server when we started it.\n",
    "\n",
    "client = MlflowClient(tracking_uri=\"http://127.0.0.1:5000\")\n",
    "\n",
    "#it allows programmatic interaction with the MLflow tracking server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons maintenant une interface client vers le serveur de suivi qui peut à la fois envoyer des données au serveur de suivi et en récupérer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Experiment: artifact_location='mlflow-artifacts:/0', creation_time=1725646407256, experiment_id='0', last_update_time=1725646407256, lifecycle_stage='active', name='Default', tags={}>]\n"
     ]
    }
   ],
   "source": [
    "all_experiments = client.search_experiments()\n",
    "\n",
    "print(all_experiments)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Créer une expérience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fournir une description de l'expérience qui apparaîtra dans l'interface utilisateur\n",
    "experiment_description = (\n",
    "    \"Ceci est un projet de prédiction de défaut de paiement des clients. \"\n",
    "    \"Cette expérience contient les modèles pour la prédiction de défaut de crédit.\"\n",
    ")\n",
    "\n",
    "# Fournir des balises (tags) recherchables qui définissent les caractéristiques des exécutions (Runs)\n",
    "# qui feront partie de cette expérience\n",
    "experiment_tags = {\n",
    "    \"project_name\": \"credit-default-prediction\",\n",
    "    \"business_unit\": \"risk-management\",\n",
    "    \"team\": \"data-science\",\n",
    "    \"project_quarter\": \"Q3-2023\",\n",
    "    \"mlflow.note.content\": experiment_description,\n",
    "}\n",
    "\n",
    "# Créer l'expérience en fournissant un nom unique\n",
    "credit_default_experiment = client.create_experiment(\n",
    "    name=\"Credit_Default_Models\", tags=experiment_tags\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_experiment_id': '892581525100417762', '_name': 'Apple_Models', '_artifact_location': 'mlflow-artifacts:/892581525100417762', '_lifecycle_stage': 'active', '_tags': {'mlflow.note.content': 'This is the grocery forecasting project. This experiment contains the produce models for apples.', 'project_name': 'grocery-forecasting', 'project_quarter': 'Q3-2023', 'store_dept': 'produce', 'team': 'stores-ml'}, '_creation_time': 1725647809507, '_last_update_time': 1725647809507}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Utiliser search_experiments() pour rechercher les expériences par la balise project_name\n",
    "\n",
    "credit_default_experiment = client.search_experiments(\n",
    "    filter_string=\"tags.`project_name` = 'credit-default-prediction'\"\n",
    ")\n",
    "\n",
    "print(vars(credit_default_experiment[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger les données\n",
    "data = pd.read_csv(\"Loan_Data(1).csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>credit_lines_outstanding</th>\n",
       "      <th>loan_amt_outstanding</th>\n",
       "      <th>total_debt_outstanding</th>\n",
       "      <th>income</th>\n",
       "      <th>years_employed</th>\n",
       "      <th>fico_score</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8153374</td>\n",
       "      <td>0</td>\n",
       "      <td>5221.545193</td>\n",
       "      <td>3915.471226</td>\n",
       "      <td>78039.38546</td>\n",
       "      <td>5</td>\n",
       "      <td>605</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7442532</td>\n",
       "      <td>5</td>\n",
       "      <td>1958.928726</td>\n",
       "      <td>8228.752520</td>\n",
       "      <td>26648.43525</td>\n",
       "      <td>2</td>\n",
       "      <td>572</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2256073</td>\n",
       "      <td>0</td>\n",
       "      <td>3363.009259</td>\n",
       "      <td>2027.830850</td>\n",
       "      <td>65866.71246</td>\n",
       "      <td>4</td>\n",
       "      <td>602</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4885975</td>\n",
       "      <td>0</td>\n",
       "      <td>4766.648001</td>\n",
       "      <td>2501.730397</td>\n",
       "      <td>74356.88347</td>\n",
       "      <td>5</td>\n",
       "      <td>612</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4700614</td>\n",
       "      <td>1</td>\n",
       "      <td>1345.827718</td>\n",
       "      <td>1768.826187</td>\n",
       "      <td>23448.32631</td>\n",
       "      <td>6</td>\n",
       "      <td>631</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  credit_lines_outstanding  loan_amt_outstanding  \\\n",
       "0      8153374                         0           5221.545193   \n",
       "1      7442532                         5           1958.928726   \n",
       "2      2256073                         0           3363.009259   \n",
       "3      4885975                         0           4766.648001   \n",
       "4      4700614                         1           1345.827718   \n",
       "\n",
       "   total_debt_outstanding       income  years_employed  fico_score  default  \n",
       "0             3915.471226  78039.38546               5         605        0  \n",
       "1             8228.752520  26648.43525               2         572        1  \n",
       "2             2027.830850  65866.71246               4         602        0  \n",
       "3             2501.730397  74356.88347               5         612        0  \n",
       "4             1768.826187  23448.32631               6         631        0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging our first runs with MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function call sets the global tracking URI for the current session.\n",
    "# It’s a convenient way to configure the tracking server URI without creating a separate client instance.\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets the current active experiment to the \"Apple_Models\" experiment and\n",
    "# returns the Experiment metadata\n",
    "# Définir l'expérience active pour votre projet\n",
    "customer_default_experiment = mlflow.set_experiment(\"Client_Default_Prediction\")\n",
    "\n",
    "# Define a run name for this iteration of training.\n",
    "# If this is not set, a unique name will be auto-generated for your run.\n",
    "run_name = \"default_rf_test\"\n",
    "\n",
    "# Define an artifact path that the model will be saved to.\n",
    "# Définir le chemin des artefacts\n",
    "artifact_path = \"rf_default_model\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alban\\OneDrive\\Documents\\MLolp\\projet-main\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "c:\\Users\\alban\\OneDrive\\Documents\\MLolp\\projet-main\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2024/09/07 09:08:28 INFO mlflow.tracking._tracking_service.client: 🏃 View run random_forest_default_prediction at: http://127.0.0.1:5000/#/experiments/0/runs/bb79a13ebccd4ee8a36b45ae9326efdf.\n",
      "2024/09/07 09:08:28 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:5000/#/experiments/0.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "\n",
    "# Diviser les données en caractéristiques (X) et cible (y)\n",
    "X = data.drop(columns=[\"customer_id\", \"default\"])  # Enlever les colonnes 'customer_id' et 'default'\n",
    "y = data[\"default\"]\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Paramètres du modèle RandomForestClassifier\n",
    "params = {\n",
    "    \"n_estimators\": 100,\n",
    "    \"max_depth\": 6,\n",
    "    \"min_samples_split\": 10,\n",
    "    \"min_samples_leaf\": 4,\n",
    "    \"bootstrap\": True,\n",
    "    \"oob_score\": False,\n",
    "    \"random_state\": 888,\n",
    "}\n",
    "\n",
    "# Entraîner le modèle RandomForestClassifier\n",
    "rf = RandomForestClassifier(class_weight='balanced',**params)\n",
    "\n",
    "# Ajuster le modèle sur les données d'entraînement\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Prédire sur l'ensemble de validation\n",
    "y_pred = rf.predict(X_val)\n",
    "\n",
    "# Calculer les métriques de classification\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "precision = precision_score(y_val, y_pred)\n",
    "recall = recall_score(y_val, y_pred)\n",
    "\n",
    "# Assembler les métriques dans une collection pour les enregistrer\n",
    "metrics = {\"accuracy\": accuracy, \"f1_score\": f1, \"precision\": precision, \"recall\": recall}\n",
    "\n",
    "# Démarrer le contexte d'exécution MLflow\n",
    "with mlflow.start_run(run_name=\"random_forest_default_prediction\") as run:\n",
    "    # Enregistrer les paramètres utilisés pour l'entraînement du modèle\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Enregistrer les métriques de performance calculées\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    # Enregistrer une instance du modèle entraîné pour une utilisation ultérieure\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=rf, input_example=X_val, artifact_path=\"random_forest_model\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.995875\n",
      "Validation Accuracy: 0.9915\n"
     ]
    }
   ],
   "source": [
    "# Prédire sur l'ensemble d'entraînement\n",
    "y_train_pred = rf.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "# Afficher les scores de précision\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Validation Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alban\\OneDrive\\Documents\\MLolp\\projet-main\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "c:\\Users\\alban\\OneDrive\\Documents\\MLolp\\projet-main\\.venv\\Lib\\site-packages\\mlflow\\types\\utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2024/09/07 09:20:49 INFO mlflow.tracking._tracking_service.client: 🏃 View run logistic_regression_run_1 at: http://127.0.0.1:5000/#/experiments/286315274138648484/runs/4e7c2243f07a456cb25a630e9a05033e.\n",
      "2024/09/07 09:20:49 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:5000/#/experiments/286315274138648484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run completed with parameters: {'C': 1.0, 'solver': 'liblinear', 'random_state': 42, 'class_weight': 'balanced'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      1652\n",
      "           1       0.91      0.98      0.94       348\n",
      "\n",
      "    accuracy                           0.98      2000\n",
      "   macro avg       0.95      0.98      0.96      2000\n",
      "weighted avg       0.98      0.98      0.98      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "from sklearn.linear_model import LogisticRegression  # Importer LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report  # Importer classification_report\n",
    "\n",
    "# Définir l'URI de suivi\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "# Créer ou sélectionner l'expérience pour la régression logistique\n",
    "mlflow.set_experiment(\"LogisticRegression_Models\")\n",
    "\n",
    "# Définir les paramètres du modèle\n",
    "params = {\"C\": 1.0, \"solver\": 'liblinear', \"random_state\": 42, \"class_weight\": 'balanced'}\n",
    "\n",
    "# Démarrer un run pour entraîner le modèle avec les paramètres définis\n",
    "with mlflow.start_run(run_name=\"logistic_regression_run_1\"):\n",
    "    # Entraîner le modèle de régression logistique\n",
    "    lr_model = LogisticRegression(**params)\n",
    "    lr_model.fit(X_train, y_train)\n",
    "\n",
    "    # Prédire sur l'ensemble de validation\n",
    "    y_pred = lr_model.predict(X_val)\n",
    "\n",
    "    # Calculer les métriques de classification\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    precision = precision_score(y_val, y_pred)\n",
    "    recall = recall_score(y_val, y_pred)\n",
    "\n",
    "    # Assembler les métriques dans une collection pour les enregistrer\n",
    "    metrics = {\"accuracy\": accuracy, \"f1_score\": f1, \"precision\": precision, \"recall\": recall}\n",
    "\n",
    "    # Enregistrer les paramètres et les métriques dans MLflow\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    # Enregistrer le modèle entraîné comme artefact\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=lr_model, input_example=X_val, artifact_path=\"logistic_regression_model\"\n",
    "    )\n",
    "\n",
    "    # Afficher le rapport de classification\n",
    "    print(f\"Run completed with parameters: {params}\")\n",
    "    print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"random_forest_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(rf, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
